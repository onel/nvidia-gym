lc_judge:
  resources_servers:
    equivalence_llm_judge:
      entrypoint: app.py
      judge_model_server:
        type: responses_api_models
        name: policy_model
      judge_responses_create_params:
        input: []
      judge_prompt_template_fpath: prompt_templates/lc_judge.txt
      judge_endpoint_max_concurrency: 64
      judge_system_message: null
      judge_equal_label: CORRECT
      judge_not_equal_label: INCORRECT
      check_twice_swap: false
      reward_if_swap_fails: 0.0
      question_extract_regex: ^QUESTION:\s*(.*)$
      response_extract_regex: null
      domain: knowledge
      verified: false
lc_judge_simple_agent:
  responses_api_agents:
    simple_agent:
      entrypoint: app.py
      resources_server:
        type: resources_servers
        name: lc_judge
      model_server:
        type: responses_api_models
        name: policy_model
      datasets:
      - name: example
        type: example
        license: TBD
        jsonl_fpath: resources_servers/equivalence_llm_judge/data/example.jsonl
